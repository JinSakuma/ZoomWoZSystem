{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a={'topic': 'aiueo'}\n",
    "'topic' in a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import MeCab\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertJapaneseTokenizer, BertModel, BertForMaskedLM, BertConfig\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = BertConfig.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking', output_attentions=True)\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
    "model = BertModel.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking', config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_tokenizer(input_text):\n",
    "    return tokenizer.encode(input_text, max_length=max_len, return_tensors='pt')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        # BERTモジュール\n",
    "        self.bert = model  # 日本語学習済みのBERTモデル\n",
    "\n",
    "        # headにクラス予測を追加\n",
    "        # 入力はBERTの出力特徴量の次元768、出力は10クラス\n",
    "        self.cls = nn.Linear(in_features=768, out_features=10)\n",
    "\n",
    "        # 重み初期化処理\n",
    "        nn.init.normal_(self.cls.weight, std=0.02)\n",
    "        nn.init.normal_(self.cls.bias, 0)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        '''\n",
    "        input_ids： [batch_size, sequence_length]の文章の単語IDの羅列\n",
    "        '''\n",
    "\n",
    "        # BERTの基本モデル部分の順伝搬\n",
    "        # 順伝搬させる\n",
    "        result = self.bert(input_ids)  # reult は、sequence_output, pooled_output\n",
    "\n",
    "        # sequence_outputの先頭の単語ベクトルを抜き出す\n",
    "        vec_0 = result[0]  # 最初の0がsequence_outputを示す\n",
    "        vec_0 = vec_0[:, 0, :]  # 全バッチ。先頭0番目の単語の全768要素\n",
    "        vec_0 = vec_0.view(-1, 768)  # sizeを[batch_size, hidden_size]に変換\n",
    "        output = self.cls(vec_0)  # 全結合層\n",
    "\n",
    "        return output, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BertClassifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"/Users/jinsakuma/Downloads/model_gpu_v4.3.3.pth\"\n",
    "load_weights = torch.load(model_path, map_location={'cuda:0': 'cpu'})\n",
    "net.load_state_dict(load_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "max_len=30\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# input_text=\"君の名はの評価は何点くらいなの\"\n",
    "input_text=\"\"\n",
    "token = bert_tokenizer(input_text)\n",
    "token = token.unsqueeze(0)\n",
    "output, attentions = net(token.to(device))\n",
    "_, pred = torch.max(output, 1)\n",
    "\n",
    "sm = torch.nn.Softmax(dim=1)\n",
    "print(pred.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
